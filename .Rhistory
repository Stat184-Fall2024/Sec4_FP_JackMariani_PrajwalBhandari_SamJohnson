geom_vline(xintercept = mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev), color = 'blue') +
labs(
x = 'Margin Voters Per Electoral Vote',
y = 'Number of Outcomes in Simulation',
title = 'Distribution of Margin Voters per Electoral Vote\n (20,000 Bootstrapped Values Per Group)'
) +
annotate(
'text',
x = mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev) + 7500,
y = 15000,
label = paste0('High\n Margin\n Mean\n',
round(mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev),1)),
color = 'red',
angle = 0
) +
annotate(
'text',
x = mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev) + 10000,
y = 15000,
label = paste0('Low\n Margin\n Mean\n',
round(mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev), 1)),
color = 'blue',
angle = 0,
vjust = 0.5
)
View(bstrap_high_margin)
# we now plot a histogram  and also review the numerical results
ggplot() +
geom_histogram(aes((win_margin_votes/total_ev)), data = bstrap_high_margin, bins = 80, alpha = 0.4, fill = 'red') +
geom_histogram(aes((win_margin_votes/total_ev)), data = bstrap_low_margin, bins = 80, alpha = 0.4, fill = 'blue') +
geom_vline(xintercept = mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev), color = 'red') +
geom_vline(xintercept = mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev), color = 'blue') +
labs(
x = 'Margin Voters Per Electoral Vote',
y = 'Number of Outcomes in Simulation',
title = 'Distribution of Margin Voters per Electoral Vote\n (200,000 Bootstrapped Values Per Group)'
) +
annotate(
'text',
x = mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev) + 7500,
y = 15000,
label = paste0('High\n Margin\n Mean\n',
round(mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev),1)),
color = 'red',
angle = 0
) +
annotate(
'text',
x = mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev) + 10000,
y = 15000,
label = paste0('Low\n Margin\n Mean\n',
round(mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev), 1)),
color = 'blue',
angle = 0,
vjust = 0.5
)
# we now plot a histogram  and also review the numerical results
ggplot() +
geom_histogram(aes((win_margin_votes/total_ev)), data = bstrap_high_margin, bins = 100, alpha = 0.4, fill = 'red') +
geom_histogram(aes((win_margin_votes/total_ev)), data = bstrap_low_margin, bins = 100, alpha = 0.4, fill = 'blue') +
geom_vline(xintercept = mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev), color = 'red') +
geom_vline(xintercept = mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev), color = 'blue') +
labs(
x = 'Margin Voters Per Electoral Vote',
y = 'Number of Outcomes in Simulation',
title = 'Distribution of Margin Voters per Electoral Vote\n (200,000 Bootstrapped Values Per Group)'
) +
annotate(
'text',
x = mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev) + 7500,
y = 15000,
label = paste0('High\n Margin\n Mean\n',
round(mean(bstrap_high_margin$win_margin_votes/bstrap_high_margin$total_ev),1)),
color = 'red',
angle = 0
) +
annotate(
'text',
x = mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev) + 10000,
y = 15000,
label = paste0('Low\n Margin\n Mean\n',
round(mean(bstrap_low_margin$win_margin_votes/bstrap_low_margin$total_ev), 1)),
color = 'blue',
angle = 0,
vjust = 0.5
)
init_table_bstrap_num_results <- rbind(bstrap_high_margin, bstrap_low_margin) %>%
mutate(
high_or_low = if_else(win_margin_percent > 8, 'High', 'Low')
) %>%
group_by(high_or_low) %>%
summarize(
mean_vote_per_ev = mean(win_margin_votes/total_ev),
sd_vote_per_ev = sd(win_margin_votes/total_ev),
# confidence intervals
lower_ci = mean(win_margin_votes / total_ev) - qt(0.975, df = n() - 1) *
(sd(win_margin_votes / total_ev) / sqrt(n())),
upper_ci = mean(win_margin_votes / total_ev) + qt(0.975, df = n() - 1) *
(sd(win_margin_votes / total_ev) / sqrt(n()))
)
init_table_bstrap_num_results <- rbind(bstrap_high_margin, bstrap_low_margin) %>%
mutate(
high_or_low = if_else(win_margin_percent > 8, 'High', 'Low')
) %>%
group_by(high_or_low) %>%
summarize(
mean_vote_per_ev = mean(win_margin_votes/total_ev),
sd_vote_per_ev = sd(win_margin_votes/total_ev),
# confidence intervals
lower_ci = mean(win_margin_votes / total_ev) - qt(0.975, df = n() - 1) *
(sd_vote_per_ev/ sqrt(n())),
upper_ci = mean(win_margin_votes / total_ev) + qt(0.975, df = n() - 1) *
(sd_vote_per_ev / sqrt(n()))
)
svm_data <- data %>%
mutate(
state = as.numeric(row_number() %% 51),
third_party_swing_potential = if_else(third_party_swing_potential == TRUE, 1 , 0)
)
View(svm_data)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.8*n) #train on 80% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.8*n) #train on 80% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
svm_data <- data %>%
mutate(
state = as.numeric(row_number() %% 51),
third_party_swing_potential = if_else(third_party_swing_potential == TRUE, 1 , 0),
winning_party = as.factor(winning_party)
)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.8*n) #train on 80% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
svm_data <- data %>%
mutate(
state = as.numeric(row_number() %% 51),
third_party_swing_potential = if_else(third_party_swing_potential == TRUE, 1 , 0),
winning_party = as.factor(winning_party)
)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.7*n) #train on 70% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
print(confusion_matrix)
# create numeric data frame by mutating original data frame
svm_data <- data %>%
mutate(
state = as.numeric(row_number() %% 51),
third_party_swing_potential = if_else(third_party_swing_potential == TRUE, 1 , 0),
winning_party = as.factor(winning_party)
)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.5*n) #train on 70% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.5*n) #train on 70% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
print(accuracy)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.1*n) #train on 70% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
View(training_data)
View(training_data)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.5*n) #train on 70% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
print(confusion_matrix)
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- kable(
init_table_bstrap_num_results,
caption = 'Numerical Results for Bootstrap Simulations',
align = 'c'
) %>% kableExtra::kable_classic()
view(polished_bstrap_res)
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- taybl(init_table_bstrap_num_results) %>%
kable(
init_table_bstrap_num_results,
caption = 'Numerical Results for Bootstrap Simulations',
align = 'c'
) %>% kableExtra::kable_classic()
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
init_table_bstrap_num_results,
caption = 'Numerical Results for Bootstrap Simulations',
align = 'c'
) %>% kableExtra::kable_classic()
polished_bstrap_res
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
init_table_bstrap_num_results,
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
"Lower 95% CI",
"Upper 95% CI"),
align = 'c'
) %>%
kableExtra::kable_classic(
)
polished_bstrap_res
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
init_table_bstrap_num_results,
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
"Lower 95% CI",
"Upper 95% CI"),
align = 'c'
) %>%
kableExtra::kable_classic()
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
init_table_bstrap_num_results,
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
"Lower 95% CI",
"Upper 95% CI"),
align = 'c'
) %>%
kableExtra::kable_classic()
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
"Lower 95% CI",
"Upper 95% CI"
),
align = 'c'
) %>%
kableExtra::kable_classic()
polished_bstrap_res
init_table_bstrap_num_results <- rbind(bstrap_high_margin, bstrap_low_margin) %>%
mutate(
high_or_low = if_else(win_margin_percent > 8, 'High', 'Low')
) %>%
group_by(high_or_low) %>%
summarize(
mean_vote_per_ev = mean(win_margin_votes/total_ev),
sd_vote_per_ev = sd(win_margin_votes/total_ev),
se_vote_per_ev = sd(win_margin_votes / total_ev) / sqrt(n()), # standard error
# confidence intervals
lower_ci = mean_vote_per_ev - qt(0.975, df = n() - 1) * se_vote_per_ev,
upper_ci = mean_vote_per_ev + qt(0.975, df = n() - 1) * se_vote_per_ev
)
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
"Lower 95% CI",
"Upper 95% CI"
),
align = 'c'
) %>%
kableExtra::kable_classic()
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
'SE Vote Per EV',
"Lower 95% CI",
"Upper 95% CI"
),
align = 'c'
) %>%
kableExtra::kable_classic()
polished_bstrap_res
svm_data <- data %>%
mutate(
state = as.numeric(row_number() %% 51),
third_party_swing_potential = if_else(third_party_swing_potential == TRUE, 1 , 0),
winning_party = as.factor(winning_party)
)
# split training data
n <- nrow(svm_data)
train_set <- sample(1:n, size = 0.7*n) #train on 70% of the data
training_data <- svm_data[train_set, ]
testing_data <- svm_data[-train_set, ]
# run model and predict
svm_model <- svm(winning_party ~ ., data = training_data, kernel = 'linear') # linear kernel splits the data linearly into groups
true_results <- testing_data$winning_party
prediction <- predict(svm_model, newdata = testing_data)
# check results
confusion_matrix <- table(Predicted = prediction, Actual = true_results)
print(confusion_matrix)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(accuracy)
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
caption = 'Numerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
'SE Vote Per EV',
"Lower 95% CI",
"Upper 95% CI"
),
align = 'c'
) %>%
kableExtra::kable_classic(full_width = FALSE)
# bstrap_res_table <-; TODO: polish the table
polished_bstrap_res <- tibble(init_table_bstrap_num_results) %>%
kable(
caption = '\t\t\t\t\t\t\tNumerical Results for Bootstrap Simulations',
col.names = c("High or Low Margin",
"Mean Vote per EV",
"SD Vote per EV",
'SE Vote Per EV',
"Lower 95% CI",
"Upper 95% CI"
),
align = 'c'
) %>%
kableExtra::kable_classic(full_width = FALSE)
polished_bstrap_res
initial_table
# nice formatting with kable
kable(
initial_table,
caption = 'Frequency of National Winner Predictions when MI, PA, WI Vote together',
align = 'c'
) %>% kableExtra::kable_classic()
# nice formatting with kable
kable(
initial_table,
caption = 'Frequency of National Winner Predictions when MI, PA, WI Vote together',
align = 'c'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
confusion_matrix  %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
(
full_width = FALSE
)
# polish confusion matrix table
confusion_matrix %>% adorn_title(
placement = 'combined',
row_name = "Correct Prediction",
col_name = 'Voted Together'
) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
data.frame(confusion_matrix) %>% adorn_title(
placement = 'combined',
row_name = "Correct Prediction",
col_name = 'Voted Together'
) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
data.frame(confusion_matrix) %>% adorn_title(
placement = 'combined',
row_name = "Actual",
col_name = 'Predicton'
) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
data.frame(confusion_matrix) %>% adorn_title(
placement = 'combined',
row_name = "",
col_name = 'Predicton'
) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
data.frame(confusion_matrix) %>% adorn_title(
placement = 'combined',
row_name = "Prediction",
col_name = ''
) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
data.frame(confusion_matrix) %>% adorn_title(
placement = 'combined',
row_name = "Prediction",
) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
# polish confusion matrix table
data.frame(confusion_matrix) %>%
kable(
caption = 'Confusion Matrix for Testing Results from 70% Data Split'
) %>%
kableExtra::kable_classic(
full_width = FALSE
)
